{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as spy\n",
    "from scipy import linalg\n",
    "import pylab as py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "This module generates trajectories of a simple two dimensional toy model for testing purposes.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "__all__ = ['generate_test_data']\n",
    "\n",
    "def _gradient(x, y):\n",
    "    return (x * x - 1.0) * 4.0 * x + 0.5, (4.0 * y * y - 7.0) * y\n",
    "\n",
    "def _bd(x0, y0, length, dt=0.005):\n",
    "    coeff_A = dt\n",
    "    coeff_B = np.sqrt(2.0 * dt)\n",
    "    x = [x0]\n",
    "    y = [y0]\n",
    "    for _i in range(1, length):\n",
    "        dx, dy = _gradient(x[-1], y[-1])\n",
    "        x.append(x[-1] - coeff_A * dx + coeff_B * np.random.normal())\n",
    "        y.append(y[-1] - coeff_A * dy + coeff_B * np.random.normal())\n",
    "    return np.array([[_x, _y] for _x, _y in zip(x, y)], dtype=np.float64)\n",
    "\n",
    "def generate_test_data(traj_length=20000, num_trajs=5):\n",
    "    r\"\"\"\n",
    "    This functions handles the test data generation via Brownian dynamics simulations with\n",
    "    randomized starting configurations.\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj_length : int, optional, default=20000\n",
    "        Length of a single trajectory.\n",
    "    num_trajs : int, optional, default=5\n",
    "        Number of independent trajectories.\n",
    "    Returns\n",
    "    -------\n",
    "    trajs : list of numpy.ndarray(shape=(traj_length, 2), dtype=numpy.float64) objects\n",
    "        Time series of configurations of the toy model.\n",
    "    \"\"\"\n",
    "    trajs = []\n",
    "    for _i in range(num_trajs):\n",
    "        trajs.append(_bd(3.0 * np.random.rand() - 1.5, 3.0 * np.random.rand() - 1.5, traj_length))\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TIMESCALES\n",
    "\"\"\"\n",
    "\n",
    "def stat(T):\n",
    "    w, v = np.linalg.eig(T.T)\n",
    "    \n",
    "    j_stat =np.argmin(abs(w-1.0))\n",
    "    p_stat=v[:,j_stat].real\n",
    "    p_stat /= p_stat.sum()\n",
    "    return p_stat\n",
    "\n",
    "\n",
    "def implied_timescales(T_lag,lag):\n",
    "    \"\"\"\n",
    "    Calculates timescale_i(k*lag)=\n",
    "    \n",
    "    INPUT:\n",
    "        - T = A markov transition matrix at a lagtime lag.\n",
    "        - lag = reference lagtime we are considering.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    eig_val, eig_vec=np.linalg.eig(T)\n",
    "    L=[]\n",
    "    for i in range(len(eig_val)):\n",
    "        L.append(-(lag)/(np.log(np.absolute(eig_val[i]))))\n",
    "    return(L)\n",
    "\n",
    "\n",
    "def plot_timescales(T,LAG):\n",
    "    \"\"\"\n",
    "    Functio\n",
    "    \n",
    "    INPUT:\n",
    "        - T = A markov transition matrix.\n",
    "        - LAG = A list of the lagtimes in which we plot the \n",
    "    \"\"\"\n",
    "    \n",
    "    eig=np.linalg.eig(T)\n",
    "    k=len(eig[0])\n",
    "    \n",
    "    d=len(T)\n",
    "    t=[]\n",
    "    \n",
    "    for i in range(k):\n",
    "        t.append([])\n",
    "        \n",
    "    for lag in LAG:\n",
    "        t_lag=implied_timescales(T,lag)\n",
    "        for j in range(k):\n",
    "            if -100<t_lag[j]<100:\n",
    "                (t[j]).append(t_lag[j])\n",
    "            else:\n",
    "                (t[j]).append(0)\n",
    "    for i in range(len(t)):\n",
    "        py.plot(LAG,t[i],'o',linestyle='-')\n",
    "    py.xlabel('Lag time')\n",
    "    py.ylabel('Implied timescale')\n",
    "    py.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TICA\n",
    "\"\"\"\n",
    "\n",
    "def make_data_mean_free(X):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_col = len(X[0])\n",
    "\n",
    "    for j in range(n_col):\n",
    "        med=((X[:,j]).sum())/(len(X[:,j]))\n",
    "        X[:,j] -= med\n",
    "    return X\n",
    "\n",
    "def TICA(X,lag):\n",
    "    \"\"\"\n",
    "    Time-lagged/ time-structure-based independent component analysis.\n",
    "    \n",
    "    INPUT:\n",
    "        - X = As input, we consider a d-dimensional vector, called r(t)=(ri(t))i=1,...,D. \n",
    "        Here, t is an integer from {1...N} denoting the time step. That is, we have a N x D matrix.\n",
    "        \n",
    "    OUTPUT:\n",
    "        - \n",
    "    \"\"\"\n",
    "    \n",
    "    X_ = np.copy(X)\n",
    "    X_ = make_data_mean_free(X)\n",
    "    \n",
    "    T=len(X)\n",
    "    D=len(X[0])\n",
    "    \n",
    "    X_0 = X_[[i for i in range(T-lag)],:]\n",
    "    X_lag = X_[[lag+i for i in range(T-lag)],:]\n",
    "    \n",
    "    #Covariance matrices\n",
    "    C_0 = (1/(T-lag-1))*(np.dot(np.transpose(X_0),X_0))\n",
    "    C_lag = (1/(T-lag-1))*(np.dot(np.transpose(X_0),X_lag))\n",
    "    \n",
    "    #Symmetrized time-lagged covariance matrix\n",
    "    C_lag = 1/2 * (C_lag + np.transpose(C_lag))\n",
    "    \n",
    "    #Eigenvalue problem --> C_lag * U = eig_val * C_0 * U]\n",
    "    U = spy.linalg.eig(C_lag,C_0)[1]\n",
    "    \n",
    "    #Projection onto the TICA space\n",
    "    Z = np.dot(X_,U)\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# kmeans clustering algorithm\n",
    "# data = set of data points\n",
    "# k = number of clusters\n",
    "# c = initial list of centroids (if provided)\n",
    "#\n",
    "def kmeans(data, k, c):\n",
    "    centroids = []\n",
    "\n",
    "    centroids = randomize_centroids(data, centroids, k)  \n",
    "\n",
    "    old_centroids = [[] for i in range(k)] \n",
    "\n",
    "    iterations = 0\n",
    "    while not (has_converged(centroids, old_centroids, iterations)):\n",
    "        iterations += 1\n",
    "\n",
    "        clusters = [[] for i in range(k)]\n",
    "\n",
    "        # assign data points to clusters\n",
    "        clusters = euclidean_dist(data, centroids, clusters)\n",
    "\n",
    "        # recalculate centroids\n",
    "        index = 0\n",
    "        for cluster in clusters:\n",
    "            old_centroids[index] = centroids[index]\n",
    "            centroids[index] = np.mean(cluster, axis=0).tolist()\n",
    "            index += 1\n",
    "    print(\"The total number of data instances is: \" + str(len(data)))\n",
    "    print(\"The total number of iterations necessary is: \" + str(iterations))\n",
    "    print(\"The means of each cluster are: \" + str(centroids))\n",
    "    print(\"The clusters are as follows:\")\n",
    "    for cluster in clusters:\n",
    "        print(\"Cluster with a size of \" + str(len(cluster)) + \" starts here:\")\n",
    "        print(np.array(cluster).tolist())\n",
    "        print(\"Cluster ends here.\")\n",
    "\n",
    "    return\n",
    "\n",
    "# Calculates euclidean distance between\n",
    "# a data point and all the available cluster\n",
    "# centroids.      \n",
    "def euclidean_dist(data, centroids, clusters):\n",
    "    for instance in data:  \n",
    "        # Find which centroid is the closest\n",
    "        # to the given data point.\n",
    "        mu_index = min([(i[0], np.linalg.norm(instance-centroids[i[0]])) \\\n",
    "                            for i in enumerate(centroids)], key=lambda t:t[1])[0]\n",
    "        try:\n",
    "            clusters[mu_index].append(instance)\n",
    "        except KeyError:\n",
    "            clusters[mu_index] = [instance]\n",
    "\n",
    "    # If any cluster is empty then assign one point\n",
    "    # from data set randomly so as to not have empty\n",
    "    # clusters and 0 means.        \n",
    "    for cluster in clusters:\n",
    "        if not cluster:\n",
    "            cluster.append(data[np.random.randint(0, len(data), size=1)].flatten().tolist())\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# randomize initial centroids\n",
    "def randomize_centroids(data, centroids, k):\n",
    "    for cluster in range(0, k):\n",
    "        centroids.append(data[np.random.randint(0, len(data), size=1)].flatten().tolist())\n",
    "    return centroids\n",
    "\n",
    "\n",
    "# check if clusters have converged    \n",
    "def has_converged(centroids, old_centroids, iterations):\n",
    "    MAX_ITERATIONS = 1000\n",
    "    if iterations > MAX_ITERATIONS:\n",
    "        return True\n",
    "    return old_centroids == centroids\n",
    "\n",
    "def kmeans2(data, k, c):\n",
    "    centroids = []\n",
    "\n",
    "    centroids = randomize_centroids(data, centroids, k)  \n",
    "\n",
    "    old_centroids = [[] for i in range(k)] \n",
    "\n",
    "    iterations = 0\n",
    "    while not (has_converged(centroids, old_centroids, iterations)):\n",
    "        iterations += 1\n",
    "\n",
    "        clusters = [[] for i in range(k)]\n",
    "\n",
    "        # assign data points to clusters\n",
    "        clusters = euclidean_dist(data, centroids, clusters)\n",
    "\n",
    "        # recalculate centroids\n",
    "        index = 0\n",
    "        for cluster in clusters:\n",
    "            old_centroids[index] = centroids[index]\n",
    "            centroids[index] = np.mean(cluster, axis=0).tolist()\n",
    "            index += 1\n",
    "    return centroids,clusters\n",
    "\n",
    "def cloust_list(L, clus_0, a_0, w):\n",
    "    for i in range(len (clus_0)): \n",
    "        for k in range(len (a_0)):\n",
    "            if  all(a_0[k]==clus_0[i]):\n",
    "                L[k]=w\n",
    "    return L\n",
    "\n",
    "def Clustering(traj,nclus):\n",
    "    cen, clus = kmeans2(traj, nclus, 5)\n",
    "    L=[0 for i in range(len(traj))]\n",
    "    for  b in range(nclus):\n",
    "        cloust_list(L, clus[b],traj,b)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COUNTMATRIX\n",
    "\"\"\"\n",
    "\n",
    "def simple_countmatrix(state_trajectory,lagtime = 1):\n",
    "    \n",
    "    #Initialization\n",
    "    n_states = max(state_trajectory)+1\n",
    "    countmatrix = np.zeros((n_states, n_states), 'float')\n",
    "    \n",
    "    #Fill Up\n",
    "    pos = 0\n",
    "    next_state = state_trajectory[pos]\n",
    "    \n",
    "    while (pos+lagtime)<len(state_trajectory):\n",
    "        #Update Input\n",
    "        prev_state = next_state\n",
    "        pos += lagtime\n",
    "        next_state = state_trajectory[pos]\n",
    "        #Count\n",
    "        countmatrix[prev_state, next_state] += 1\n",
    "    \n",
    "        \n",
    "    return(countmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KOSARAJU\n",
    "\"\"\"\n",
    "\n",
    "def stat(T):\n",
    "    w, v = np.linalg.eig(T.T)\n",
    "    \n",
    "    j_stat =np.argmin(abs(w-1.0))\n",
    "    p_stat=v[:,j_stat].real\n",
    "    p_stat /= p_stat.sum()\n",
    "    return p_stat\n",
    "\n",
    "def obtain_active_set(T):\n",
    "    \"\"\"\n",
    "    Function for other parts of the project. It gets the biggest connected component of the matrix \n",
    "    that we are given.\n",
    "    \n",
    "    INPUT:\n",
    "        - T = The probability transition matrix of the markov model.\n",
    "    \n",
    "    OUTPUT:\n",
    "        - C = A square matrix. The biggest connected component of the matrix.\n",
    "        - L = A list of vertices. The states of T that correspond to the biggest component.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    b=0\n",
    "    j=0\n",
    "    components=kosarajus_algo2(T)\n",
    "    for i in components:\n",
    "        a=len(components[i])\n",
    "        if a>b:\n",
    "            b=a\n",
    "            j=i\n",
    "    L=list(components[j])\n",
    "    L=np.sort(L)\n",
    "    C=np.array([T[i,:] for i in L])\n",
    "    C=np.array([C[:,i] for i in L])\n",
    "    C=np.transpose(C)\n",
    "    return (C,L)\n",
    "\n",
    "def Assign2(u,root,LIST,components,M):\n",
    "    \"\"\"\n",
    "    Recursive subfunction for kosarajus\n",
    "    Strong components are to be represented by appointing a separate root vertex for each component,\n",
    "    and assigning to each vertex the root vertex of its component.\n",
    "    \n",
    "    INPUT:\n",
    "        \n",
    "        - u = An integer, which represents a vertex (in our numeration) that has to be\n",
    "        assigned to some component.\n",
    "        - root = An integer, which represents a component.\n",
    "        \n",
    "        - LIST = A list of vertices that are not yet introduced in the dictionary.\n",
    "        \n",
    "        - components = A dictionary containing the vertices (numerated from 0 to n-1), \n",
    "        each vertex associated to the root representing its component.\n",
    "        - M = A transition matrix (which is the adjacency matrix of a graph).\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "        - It just changes the dictionary components, assigning to each vertex its root.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    in_=[i for i in M[:,u]]\n",
    "    \n",
    "    if u in LIST:\n",
    "        \n",
    "        if not root in components:\n",
    "            components[root]=[u]\n",
    "        elif root in components:\n",
    "            components[root].append(u)\n",
    "        LIST.remove(u)\n",
    "            \n",
    "        for i in range(len(in_)):\n",
    "            if not(in_[i]==0):\n",
    "                Assign2(i,root,LIST,components,M)\n",
    "    return\n",
    "\n",
    "def Visit(u,Visited,L,M):\n",
    "    \"\"\"\n",
    "    Recursive subfunction for kosarajus\n",
    "    \n",
    "    INPUT:\n",
    "        \n",
    "        - u = An integer, which represents a vertex (in our numeration).\n",
    "        - Visited = A list of the vertices already visited.\n",
    "        - L = an ordered list of graph vertices, that will grow to contain each vertex once.\n",
    "        - M = A transition matrix (which is the adjacency matrix of a graph).\n",
    "    \n",
    "    OUTPUT:\n",
    "        \n",
    "        - It just adds in order vertices to the list L.\n",
    "    \n",
    "    \"\"\"\n",
    "    out=M[u,:]\n",
    "    if not(u in Visited):\n",
    "        Visited.append(u)\n",
    "        for i in range(len(out)):\n",
    "            if not(out[i]==0):\n",
    "                Visit(i,Visited,L,M)\n",
    "        L.insert(0,u) \n",
    "    return\n",
    "\n",
    "def kosarajus_algo2(M):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the vertices and their inclusion in strong components.\n",
    "    Strong components are to be represented by appointing a separate root vertex for each component,\n",
    "    and assigning to each root the list of vertices inside that component.\n",
    "    If the graph is represented as an adjacency matrix, the algorithm requires ÎŸ(V^2) time.\n",
    "    \n",
    "    INPUT:\n",
    "    \n",
    "        - M = A transition matrix (which is the adjacency matrix of a graph).\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "        - components = A dictionary containing the components (numerated from 0 to ..), \n",
    "        each root associated to a list of vertices that are part of that component.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Visited=[]\n",
    "    L=[]\n",
    "    \n",
    "    components={}\n",
    "    \n",
    "    Vertices= [i for i in range(len(M[:,1]))]\n",
    "    LIST=list(Vertices)\n",
    "    \n",
    "    for i in Vertices:\n",
    "        Visit(i,Visited,L,M)\n",
    "    for u in L:\n",
    "        Assign2(u,u,LIST,components,M)\n",
    "    return components  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REVERSIBLE ESTIMATOR\n",
    "\"\"\"\n",
    "\n",
    "def normalize(M):\n",
    "    \"\"\"\n",
    "    Subfunction for T. It normalizes the matrix given as input.\n",
    "    \n",
    "    INPUT:\n",
    "        - M = A matrix M.\n",
    "        \n",
    "    OUTPUT:\n",
    "        - M0 = The matrix M normalized, with rows that add to 1.     \n",
    "    \"\"\"\n",
    "    \n",
    "    M0=np.array(M)\n",
    "    if M0.ndim == 1:\n",
    "        s= M0.sum()\n",
    "        return np.divide(M0,s)\n",
    "        \n",
    "    elif M0.ndim == 2:\n",
    "        s=M0.sum(axis=1)\n",
    "        return np.divide(M0,s[:,np.newaxis])\n",
    "    else:\n",
    "        return \"Normalize. Wrong input\"\n",
    "\n",
    "def T_non_reversible(C):\n",
    "    \"\"\"\n",
    "    Function to get the transition matrix from the count matrix. It simply normalizes the count matrix.\n",
    "    Is easy, and useful for very large amount of data.\n",
    "    \n",
    "    INPUT:\n",
    "        - C = Count matrix.\n",
    "    \n",
    "    OUTPUT:\n",
    "        - P = The probability transition matrix of the markov model.\n",
    "    \"\"\"\n",
    "    \n",
    "    return normalize(C)\n",
    "\n",
    "def T_reversible(C,max_iterations=100,error=0.1):\n",
    "    \"\"\"\n",
    "    Function to get the transition matrix from the count matrix. It gives a matrix that is reversible.\n",
    "    That is, the markov model obtained is reversible (it satisfies the detailed balance equations).\n",
    "    Detailed balance implies that, around any closed cycle of states, there is no net flow of probability. \n",
    "    For example, it implies that, for all a, b and c,\n",
    "    T( a , b ) T( b , c ) T( c , a ) = T( a , c ) T( c , b ) T( b , a ).\n",
    "    \n",
    "    INPUT:\n",
    "        - C = Count matrix constructed with lag tau.\n",
    "        - max_iterations = maximum number of iterations we allow.\n",
    "        - error = error that we consider to understand that the iteration has converged.\n",
    "        \n",
    "    OUTPUT:\n",
    "        - P = The probability transition matrix of the markov model.\n",
    "    \"\"\"\n",
    "    \n",
    "    C_i = C.sum(axis=1) #array of the sums of the rows of C\n",
    "    C_j = C.sum(axis=0) #array of the sums of the columns of C\n",
    "    \n",
    "    P = T_non_reversible(C)\n",
    "    P = (obtain_active_set(P))[0]\n",
    "    pi = stat(P)\n",
    "    \n",
    "    P=np.multiply(P,pi)\n",
    "    X_0= P #initial state\n",
    "    \n",
    "    it=0\n",
    "    Er=0.2 #TO BE CHANGED\n",
    "    \n",
    "    while (Er > error) and (it< max_iterations):\n",
    "        Xi_0= X_0.sum(axis=1) #array of the sums of the rows of X_0\n",
    "        Xj_0= X_0.sum(axis=0) #array of the sums of the rows of X_0\n",
    "        \n",
    "        X_1= C + np.matrix.transpose(C)\n",
    "        X_1=np.divide(X_1,((C_i)/(Xi_0) + (C_j)/(Xj_0)))\n",
    "        \n",
    "        X_0 = X_1\n",
    "        it+=1\n",
    "        \n",
    "    P = normalize(X_1)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20972669, -0.19045398],\n",
       "       [ 0.16719412, -0.36483985],\n",
       "       [ 0.12435518, -0.43722798],\n",
       "       [ 0.03057095, -0.51755609],\n",
       "       [ 0.01553943, -0.52389004],\n",
       "       [ 0.11561626, -0.65183536],\n",
       "       [ 0.04705569, -0.63892038],\n",
       "       [ 0.15846572, -0.60808226],\n",
       "       [ 0.22015643, -0.72139088],\n",
       "       [ 0.3984038 , -0.64369267],\n",
       "       [ 0.44443654, -0.57878277],\n",
       "       [ 0.41381567, -0.55536294],\n",
       "       [ 0.68171859, -0.45881404],\n",
       "       [ 0.71807899, -0.3538689 ],\n",
       "       [ 0.80761448, -0.33364635],\n",
       "       [ 0.79782772, -0.22525607],\n",
       "       [ 0.69146866, -0.24455426],\n",
       "       [ 0.60749775, -0.22784587],\n",
       "       [ 0.49179127, -0.16464156],\n",
       "       [ 0.53347927, -0.15814878]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajs = generate_test_data(200, 5)\n",
    "traj0 = trajs[0]\n",
    "traj0[[i for i in range(20)],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1=TICA(traj0,1)\n",
    "t5=TICA(traj0,2)\n",
    "t10=TICA(traj0,5)\n",
    "t50=TICA(traj0,10)\n",
    "t100=TICA(traj0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L=Clustering(t1,20)\n",
    "C=simple_countmatrix(L,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PabloAgustin\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:23: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.492749966698975,\n",
       " 3.862856864079419,\n",
       " 32.112999252309329,\n",
       " 1.2998380361085582,\n",
       " 0.75384923547909699,\n",
       " 1.0132932603108802,\n",
       " 0.47778195732511958,\n",
       " 2.2379789094245646,\n",
       " 3.5651453414356564,\n",
       " 3.5651453414356564,\n",
       " 108.9130821310995,\n",
       " 1.5383854476977998,\n",
       " 20.819475224032924,\n",
       " 10.822343306422921,\n",
       " 1.2806725878698408,\n",
       " 1.4986496858271128,\n",
       " 27.318525514808691,\n",
       " 6.8043821871900674,\n",
       " 12.298716098879693,\n",
       " -inf]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=T_non_reversible(C)\n",
    "implied_timescales(T,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
