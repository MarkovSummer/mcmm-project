{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as spy\n",
    "from scipy import linalg\n",
    "import pylab as pylab\n",
    "from pyemma import msm\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "This module generates trajectories of a simple two dimensional toy model for testing purposes.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "__all__ = ['generate_test_data']\n",
    "\n",
    "def _gradient(x, y):\n",
    "    return (x * x - 1.0) * 4.0 * x + 0.5, (4.0 * y * y - 7.0) * y\n",
    "\n",
    "def _bd(x0, y0, length, dt=0.005):\n",
    "    coeff_A = dt\n",
    "    coeff_B = np.sqrt(2.0 * dt)\n",
    "    x = [x0]\n",
    "    y = [y0]\n",
    "    for _i in range(1, length):\n",
    "        dx, dy = _gradient(x[-1], y[-1])\n",
    "        x.append(x[-1] - coeff_A * dx + coeff_B * np.random.normal())\n",
    "        y.append(y[-1] - coeff_A * dy + coeff_B * np.random.normal())\n",
    "    return np.array([[_x, _y] for _x, _y in zip(x, y)], dtype=np.float64)\n",
    "\n",
    "def generate_test_data(traj_length=20000, num_trajs=5):\n",
    "    r\"\"\"\n",
    "    This functions handles the test data generation via Brownian dynamics simulations with\n",
    "    randomized starting configurations.\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj_length : int, optional, default=20000\n",
    "        Length of a single trajectory.\n",
    "    num_trajs : int, optional, default=5\n",
    "        Number of independent trajectories.\n",
    "    Returns\n",
    "    -------\n",
    "    trajs : list of numpy.ndarray(shape=(traj_length, 2), dtype=numpy.float64) objects\n",
    "        Time series of configurations of the toy model.\n",
    "    \"\"\"\n",
    "    trajs = []\n",
    "    for _i in range(num_trajs):\n",
    "        trajs.append(_bd(3.0 * np.random.rand() - 1.5, 3.0 * np.random.rand() - 1.5, traj_length))\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TIMESCALES\n",
    "\"\"\"\n",
    "\n",
    "def stat(T):\n",
    "    w, v = np.linalg.eig(T.T)\n",
    "    \n",
    "    j_stat =np.argmin(abs(w-1.0))\n",
    "    p_stat=v[:,j_stat].real\n",
    "    p_stat /= p_stat.sum()\n",
    "    return p_stat\n",
    "\n",
    "def implied_timescales(T_lag,lag):\n",
    "    \"\"\"\n",
    "    Calculates timescale_i(k*lag)=\n",
    "    \n",
    "    INPUT:\n",
    "        - T = A markov transition matrix at a lagtime lag.\n",
    "        - lag = reference lagtime we are considering.\n",
    "    \"\"\"\n",
    "    \n",
    "    eig_val, eig_vec=np.linalg.eig(T_lag)\n",
    "    eig_val = np.absolute(eig_val)\n",
    "    eig_val = np.sort(eig_val)\n",
    "    if eig_val[0] == 0:\n",
    "        eig_val[0] = eig_val[1]\n",
    "    L=[]\n",
    "    for i in range(len(eig_val)):\n",
    "        \"\"\"if (eig_val[i]==0):\n",
    "            eig_val[i] = 0.001\"\"\"\n",
    "        ti = -(lag)/(np.log(eig_val[i]))\n",
    "        \"\"\"if len(L) == 0:\n",
    "            L.append(ti)\n",
    "        else:\n",
    "            if ti < 0:\n",
    "                L.append(L[i-1])\n",
    "            elif ti > 10 * L[i-1]:\n",
    "                L.append(L[i-1])\n",
    "            else:\n",
    "                L.append(ti)\"\"\"\n",
    "        L.append(ti)\n",
    "    return(L)\n",
    "\n",
    "def plot_timescales(T,LAG):\n",
    "    \"\"\"\n",
    "    Functio\n",
    "    \n",
    "    INPUT:\n",
    "        - T = A list of markov transition matrices such that T[i] = T(lag), transition matrix at lag time lag.\n",
    "        - LAG = A list of the lagtimes in which we plot the timescales\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(T)==len(LAG):\n",
    "        k=len(LAG)\n",
    "    else:\n",
    "        return \"Input dimensions dont match\"\n",
    "    \n",
    "    kk=len(implied_timescales(T[0],LAG[0])) \n",
    "    timescale_trajs=[]\n",
    "    for i in range(kk):\n",
    "        timescale_trajs.append([])\n",
    "        \n",
    "    for l in range(k):\n",
    "        t_lag=implied_timescales(T[l],LAG[l]) #timescales at lag l\n",
    "        \n",
    "        for j in range(len(t_lag)):\n",
    "            if t_lag[j]<1000:\n",
    "                (timescale_trajs[j]).append(t_lag[j])\n",
    "            else:\n",
    "                \"\"\"(timescale_trajs[j]).append(timescale_trajs[j][-1])\"\"\"\n",
    "                (timescale_trajs[j]).append(t_lag[j])\n",
    "    \n",
    "    #plot slower n_timescales\n",
    "    \"\"\"if n_timescales < len(timescale_trajs):\n",
    "        n = n_timescales\n",
    "    else:\n",
    "        n = len(timescale_trajs)\"\"\"\n",
    "    for i in range(len(timescale_trajs)-1):\n",
    "        if len(LAG) == len(timescale_trajs[i]):\n",
    "            plt.plot(LAG,timescale_trajs[i],'o',linestyle='-')\n",
    "        else:\n",
    "            next\n",
    "    plt.xlabel('Lag time')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Implied timescale')\n",
    "    plt.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K-MEANS\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# kmeans clustering algorithm\n",
    "# data = set of data points\n",
    "# k = number of clusters\n",
    "# c = initial list of centroids (if provided)\n",
    "#\n",
    "def kmeans(data, k, c):\n",
    "    centroids = []\n",
    "\n",
    "    centroids = randomize_centroids(data, centroids, k)  \n",
    "\n",
    "    old_centroids = [[] for i in range(k)] \n",
    "\n",
    "    iterations = 0\n",
    "    while not (has_converged(centroids, old_centroids, iterations)):\n",
    "        iterations += 1\n",
    "\n",
    "        clusters = [[] for i in range(k)]\n",
    "\n",
    "        # assign data points to clusters\n",
    "        clusters = euclidean_dist(data, centroids, clusters)\n",
    "\n",
    "        # recalculate centroids\n",
    "        index = 0\n",
    "        for cluster in clusters:\n",
    "            old_centroids[index] = centroids[index]\n",
    "            centroids[index] = np.mean(cluster, axis=0).tolist()\n",
    "            index += 1\n",
    "    print(\"The total number of data instances is: \" + str(len(data)))\n",
    "    print(\"The total number of iterations necessary is: \" + str(iterations))\n",
    "    print(\"The means of each cluster are: \" + str(centroids))\n",
    "    print(\"The clusters are as follows:\")\n",
    "    for cluster in clusters:\n",
    "        print(\"Cluster with a size of \" + str(len(cluster)) + \" starts here:\")\n",
    "        print(np.array(cluster).tolist())\n",
    "        print(\"Cluster ends here.\")\n",
    "\n",
    "    return\n",
    "\n",
    "# Calculates euclidean distance between\n",
    "# a data point and all the available cluster\n",
    "# centroids.      \n",
    "def euclidean_dist(data, centroids, clusters):\n",
    "    for instance in data:  \n",
    "        # Find which centroid is the closest\n",
    "        # to the given data point.\n",
    "        mu_index = min([(i[0], np.linalg.norm(instance-centroids[i[0]])) \\\n",
    "                            for i in enumerate(centroids)], key=lambda t:t[1])[0]\n",
    "        try:\n",
    "            clusters[mu_index].append(instance)\n",
    "        except KeyError:\n",
    "            clusters[mu_index] = [instance]\n",
    "\n",
    "    # If any cluster is empty then assign one point\n",
    "    # from data set randomly so as to not have empty\n",
    "    # clusters and 0 means.        \n",
    "    for cluster in clusters:\n",
    "        if not cluster:\n",
    "            cluster.append(data[np.random.randint(0, len(data), size=1)].flatten().tolist())\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# randomize initial centroids\n",
    "def randomize_centroids(data, centroids, k):\n",
    "    for cluster in range(0, k):\n",
    "        centroids.append(data[np.random.randint(0, len(data), size=1)].flatten().tolist())\n",
    "    return centroids\n",
    "\n",
    "\n",
    "# check if clusters have converged    \n",
    "def has_converged(centroids, old_centroids, iterations):\n",
    "    MAX_ITERATIONS = 1000\n",
    "    if iterations > MAX_ITERATIONS:\n",
    "        return True\n",
    "    return old_centroids == centroids\n",
    "\n",
    "def kmeans2(data, k, c):\n",
    "    centroids = []\n",
    "\n",
    "    centroids = randomize_centroids(data, centroids, k)  \n",
    "\n",
    "    old_centroids = [[] for i in range(k)] \n",
    "\n",
    "    iterations = 0\n",
    "    while not (has_converged(centroids, old_centroids, iterations)):\n",
    "        iterations += 1\n",
    "\n",
    "        clusters = [[] for i in range(k)]\n",
    "\n",
    "        # assign data points to clusters\n",
    "        clusters = euclidean_dist(data, centroids, clusters)\n",
    "\n",
    "        # recalculate centroids\n",
    "        index = 0\n",
    "        for cluster in clusters:\n",
    "            old_centroids[index] = centroids[index]\n",
    "            centroids[index] = np.mean(cluster, axis=0).tolist()\n",
    "            index += 1\n",
    "    return centroids,clusters\n",
    "\n",
    "def cloust_list(L, clus_0, a_0, w):\n",
    "    for i in range(len (clus_0)): \n",
    "        for k in range(len (a_0)):\n",
    "            if  all(a_0[k]==clus_0[i]):\n",
    "                L[k]=w\n",
    "    return L\n",
    "\n",
    "def Clustering(traj,nclus):\n",
    "    centers, clus = kmeans2(traj, nclus, 5)\n",
    "    L=[0 for i in range(len(traj))]\n",
    "    for  b in range(nclus):\n",
    "        cloust_list(L, clus[b],traj,b)\n",
    "    return L, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COUNTMATRIX\n",
    "\"\"\"\n",
    "\n",
    "def sliding_window(traj,lag=1):\n",
    "    \"\"\"\n",
    "    Get the count matrix out of the trajectory from clusters.\n",
    "    \n",
    "    INPUT:\n",
    "        traj = A list. A sucesion of states.\n",
    "        lag = Lagtime we are considering.\n",
    "        \n",
    "    OUTPUT:\n",
    "        A count matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    dim = max(traj)+1\n",
    "    C=np.zeros([dim,dim])\n",
    "    for i in range(len(traj)-lag):\n",
    "        C[traj[i],traj[i+lag]] +=1\n",
    "        \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KOSARAJU\n",
    "\"\"\"\n",
    "\n",
    "def stat(T):\n",
    "    w, v = np.linalg.eig(T.T)\n",
    "    \n",
    "    j_stat =np.argmin(abs(w-1.0))\n",
    "    p_stat=v[:,j_stat].real\n",
    "    p_stat /= p_stat.sum()\n",
    "    return p_stat\n",
    "\n",
    "def obtain_active_set(T):\n",
    "    \"\"\"\n",
    "    Function for other parts of the project. It gets the biggest connected component of the matrix \n",
    "    that we are given.\n",
    "    \n",
    "    INPUT:\n",
    "        - T = The probability transition matrix of the markov model.\n",
    "    \n",
    "    OUTPUT:\n",
    "        - C = A square matrix. The biggest connected component of the matrix.\n",
    "        - L = A list of vertices. The states of T that correspond to the biggest component.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    b=0\n",
    "    j=0\n",
    "    components=kosarajus_algo2(T)\n",
    "    for i in components:\n",
    "        a=len(components[i])\n",
    "        if a>b:\n",
    "            b=a\n",
    "            j=i\n",
    "    L=list(components[j])\n",
    "    L=np.sort(L)\n",
    "    C=np.array([T[i,:] for i in L])\n",
    "    C=np.array([C[:,i] for i in L])\n",
    "    C=np.transpose(C)\n",
    "    return (C,L)\n",
    "\n",
    "def Assign2(u,root,LIST,components,M):\n",
    "    \"\"\"\n",
    "    Recursive subfunction for kosarajus\n",
    "    Strong components are to be represented by appointing a separate root vertex for each component,\n",
    "    and assigning to each vertex the root vertex of its component.\n",
    "    \n",
    "    INPUT:\n",
    "        \n",
    "        - u = An integer, which represents a vertex (in our numeration) that has to be\n",
    "        assigned to some component.\n",
    "        - root = An integer, which represents a component.\n",
    "        \n",
    "        - LIST = A list of vertices that are not yet introduced in the dictionary.\n",
    "        \n",
    "        - components = A dictionary containing the vertices (numerated from 0 to n-1), \n",
    "        each vertex associated to the root representing its component.\n",
    "        - M = A transition matrix (which is the adjacency matrix of a graph).\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "        - It just changes the dictionary components, assigning to each vertex its root.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    in_=[i for i in M[:,u]]\n",
    "    \n",
    "    if u in LIST:\n",
    "        \n",
    "        if not root in components:\n",
    "            components[root]=[u]\n",
    "        elif root in components:\n",
    "            components[root].append(u)\n",
    "        LIST.remove(u)\n",
    "            \n",
    "        for i in range(len(in_)):\n",
    "            if not(in_[i]==0):\n",
    "                Assign2(i,root,LIST,components,M)\n",
    "    return\n",
    "\n",
    "def Visit(u,Visited,L,M):\n",
    "    \"\"\"\n",
    "    Recursive subfunction for kosarajus\n",
    "    \n",
    "    INPUT:\n",
    "        \n",
    "        - u = An integer, which represents a vertex (in our numeration).\n",
    "        - Visited = A list of the vertices already visited.\n",
    "        - L = an ordered list of graph vertices, that will grow to contain each vertex once.\n",
    "        - M = A transition matrix (which is the adjacency matrix of a graph).\n",
    "    \n",
    "    OUTPUT:\n",
    "        \n",
    "        - It just adds in order vertices to the list L.\n",
    "    \n",
    "    \"\"\"\n",
    "    out=M[u,:]\n",
    "    if not(u in Visited):\n",
    "        Visited.append(u)\n",
    "        for i in range(len(out)):\n",
    "            if not(out[i]==0):\n",
    "                Visit(i,Visited,L,M)\n",
    "        L.insert(0,u) \n",
    "    return\n",
    "\n",
    "def kosarajus_algo2(M):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the vertices and their inclusion in strong components.\n",
    "    Strong components are to be represented by appointing a separate root vertex for each component,\n",
    "    and assigning to each root the list of vertices inside that component.\n",
    "    If the graph is represented as an adjacency matrix, the algorithm requires Ο(V^2) time.\n",
    "    \n",
    "    INPUT:\n",
    "    \n",
    "        - M = A transition matrix (which is the adjacency matrix of a graph).\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "        - components = A dictionary containing the components (numerated from 0 to ..), \n",
    "        each root associated to a list of vertices that are part of that component.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Visited=[]\n",
    "    L=[]\n",
    "    \n",
    "    components={}\n",
    "    \n",
    "    Vertices= [i for i in range(len(M[:,1]))]\n",
    "    LIST=list(Vertices)\n",
    "    \n",
    "    for i in Vertices:\n",
    "        Visit(i,Visited,L,M)\n",
    "    for u in L:\n",
    "        Assign2(u,u,LIST,components,M)\n",
    "    return components  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REVERSIBLE ESTIMATOR\n",
    "\"\"\"\n",
    "\n",
    "def normalize(M):\n",
    "    \"\"\"\n",
    "    Subfunction for T. It normalizes the matrix given as input.\n",
    "    \n",
    "    INPUT:\n",
    "        - M = A matrix M.\n",
    "        \n",
    "    OUTPUT:\n",
    "        - M0 = The matrix M normalized, with rows that add to 1.     \n",
    "    \"\"\"\n",
    "    \n",
    "    M0=np.array(M)\n",
    "    if M0.ndim == 1:\n",
    "        s= M0.sum()\n",
    "        return np.divide(M0,s)\n",
    "        \n",
    "    elif M0.ndim == 2:\n",
    "        s=M0.sum(axis=1)\n",
    "        return np.divide(M0,s[:,np.newaxis])\n",
    "    else:\n",
    "        return \"Normalize. Wrong input\"\n",
    "\n",
    "def T_non_reversible(C):\n",
    "    \"\"\"\n",
    "    Function to get the transition matrix from the count matrix. It simply normalizes the count matrix.\n",
    "    Is easy, and useful for very large amount of data.\n",
    "    \n",
    "    INPUT:\n",
    "        - C = Count matrix.\n",
    "    \n",
    "    OUTPUT:\n",
    "        - P = The probability transition matrix of the markov model.\n",
    "    \"\"\"\n",
    "    \n",
    "    return normalize(C)\n",
    "\n",
    "def T_reversible(C,max_iterations=100,error=0.1):\n",
    "    \"\"\"\n",
    "    Function to get the transition matrix from the count matrix. It gives a matrix that is reversible.\n",
    "    That is, the markov model obtained is reversible (it satisfies the detailed balance equations).\n",
    "    Detailed balance implies that, around any closed cycle of states, there is no net flow of probability. \n",
    "    For example, it implies that, for all a, b and c,\n",
    "    T( a , b ) T( b , c ) T( c , a ) = T( a , c ) T( c , b ) T( b , a ).\n",
    "    \n",
    "    INPUT:\n",
    "        - C = Count matrix constructed with lag tau.\n",
    "        - max_iterations = maximum number of iterations we allow.\n",
    "        - error = error that we consider to understand that the iteration has converged.\n",
    "        \n",
    "    OUTPUT:\n",
    "        - P = The probability transition matrix of the markov model.\n",
    "    \"\"\"\n",
    "    \n",
    "    C_i = C.sum(axis=1) #array of the sums of the rows of C\n",
    "    C_j = C.sum(axis=0) #array of the sums of the columns of C\n",
    "    \n",
    "    P = T_non_reversible(C)\n",
    "    P = (obtain_active_set(P))[0]\n",
    "    pi = stat(P)\n",
    "    \n",
    "    P=np.multiply(pi,P)\n",
    "    X_0= P #initial state\n",
    "    \n",
    "    it=0\n",
    "    Er=0.2 #TO BE CHANGED\n",
    "    \n",
    "    while (Er > error) and (it< max_iterations):\n",
    "        Xi_0= X_0.sum(axis=1) #array of the sums of the rows of X_0\n",
    "        Xj_0= X_0.sum(axis=0) #array of the sums of the rows of X_0\n",
    "        \n",
    "        \n",
    "        X_1= C + np.matrix.transpose(C)\n",
    "        if not(len(C_i)==len(Xi_0)):\n",
    "            return X_0\n",
    "        I = np.divide((C_i),(Xi_0))\n",
    "        if not(len(C_j)==len(Xj_0)):\n",
    "            return X_0\n",
    "        II = np.divide((C_j),(Xj_0))\n",
    "        denominador = I + II\n",
    "        X_1=np.divide(X_1,denominador)\n",
    "        \n",
    "        X_0 = X_1\n",
    "        it+=1\n",
    "        \n",
    "    P = normalize(X_1)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hitting_time_ij(T,i,j,steps):\n",
    "    \"\"\"\n",
    "    Calculates the hitting time between states i, j from the markov transition matrix.\n",
    "    Since p_ij is the probability of going to state j given that we are in state \n",
    "    i, the product π_i * p_ij is the long run proportion of transitions that go from state\n",
    "    i to state j.\n",
    "    \n",
    "    INPUT:\n",
    "        - T = A markov transiton matrix.\n",
    "        - i = Some state from which we start.\n",
    "        - j = Some state where we wanna arrive.\n",
    "        - steps = An integer. Max number of steps we want to consider.\n",
    "        \n",
    "    OUTPUT:\n",
    "        - A picture showing how hitting probability between i and j changes with time.\n",
    "        - Limiting probability of going from state i to state j.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    A=T.copy()\n",
    "    \n",
    "    hit_idx = (i,j)\n",
    "\n",
    "    # Make the final state an absorbing condition\n",
    "    A[hit_idx[1],:] = 0\n",
    "    A[hit_idx[1],hit_idx[1]] = 1\n",
    "\n",
    "    # Make a proper Markov matrix by row normalizing\n",
    "    A = (A.T/A.sum(axis=1)).T\n",
    "    \n",
    "    B = A.copy()\n",
    "    Z = []\n",
    "    for n in range(steps):\n",
    "        Z.append( B[hit_idx] )\n",
    "        B = np.dot(B,A)\n",
    "    \n",
    "    plt.plot(Z)\n",
    "    plt.xlabel(\"steps\")\n",
    "    plt.ylabel(\"hit probability\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MEAN FIRST PASSAGE TIMES\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def forward_commitors(T,A,B):\n",
    "    \"\"\"\n",
    "    Formally defined as the probability to hit set B rather than A\n",
    "    \n",
    "    INPUT:\n",
    "        - T = A markov transition matrix\n",
    "        - A = A subset of states.\n",
    "        - B = A subset of states.\n",
    "        \n",
    "    OUTPUT:\n",
    "    \"\"\"\n",
    "\n",
    "        \n",
    "    n = len(T)\n",
    "    \n",
    "    q=np.zeros(n)\n",
    "    q[B] = np.ones(len(B))\n",
    "    \n",
    "    B_ = [i for i in range(n) if i not in B]\n",
    "    AB_ = [i for i in B_ if i not in A]\n",
    "    \n",
    "    \n",
    "    a = np.copy(T)\n",
    "    a = a[:,AB_]\n",
    "    a = a[AB_,:]\n",
    "    \n",
    "    I=np.identity(len(a))\n",
    "    a=a-I\n",
    "    \n",
    "    b = np.copy(T)\n",
    "    b = b[:,B]\n",
    "    b = b[AB_,:]\n",
    "\n",
    "    b=b.sum(axis=1)\n",
    "    b= -1*b \n",
    "    \n",
    "    if not(len(a)==0 or len(b)==0):\n",
    "        Q = (np.linalg.lstsq(a,b))[0]\n",
    "        q[AB_] = Q\n",
    "    \n",
    "    return q        \n",
    "\n",
    "def probability_current(T,A,B):\n",
    "    \"\"\"\n",
    "    ¡¡NOT OPTIMIZED!!\n",
    "    \n",
    "    The probability current gives the averege number of reactive trajectories\n",
    "    (those going from A to B, without entering A before reaching B) that transition\n",
    "    from i to j per time unit.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(T)\n",
    "    \n",
    "    F = np.copy(T)\n",
    "    \n",
    "    q = forward_commitors(T,A,B)   \n",
    "    q_ = forward_commitors(T,B,A)\n",
    "    \n",
    "    pi=stat(T)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if j==i:\n",
    "                F[i,j]=0\n",
    "            else:\n",
    "                F[i,j] = (pi[i])*(q_[i])*(T[i,j])*(q[j])\n",
    "    \n",
    "    return F\n",
    "\n",
    "def average_current(T,A,B):\n",
    "    \"\"\"\n",
    "    ¡¡NOT OPTIMIZED!!\n",
    "    \n",
    "    Average total number of trajectories going from A to B per time unit.\n",
    "    \n",
    "    INPUT:\n",
    "        - T = A markov transition matrix.\n",
    "        - A = A subset of indices.\n",
    "        - B = A subset of indices.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f_AB = probability_current(T,A,B)\n",
    "        \n",
    "    n=len(f_AB)\n",
    "    F_AB = np.zeros([n,n])\n",
    "    \n",
    "    for i in A:\n",
    "        for j in B:\n",
    "            F_AB[i,j] = f_AB[i,j]\n",
    "    F_AB=F_AB.sum(axis=1)\n",
    "    F_AB=F_AB.sum(axis=0)\n",
    "    \n",
    "    return F_AB\n",
    "\n",
    "def transition_rates(T,A,B):\n",
    "    \"\"\"\n",
    "    ¡¡NOT OPTIMIZED!!\n",
    "    \n",
    "    The forward and backward commitor are sufficient to calculate transition rates between \n",
    "    the sets A and B\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    F_AB = average_current(T,A,B)\n",
    "    pi = stat(T)\n",
    "    q = forward_commitors(T,A,B)\n",
    "    \n",
    "    sum=0\n",
    "    \n",
    "    for j in B:\n",
    "        sum= sum + (pi[j])*(q[j])\n",
    "        \n",
    "    return (F_AB/sum)\n",
    "\n",
    "def mean_first_passage_times(T,A,B):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    t= transition_rates(T,A,B)\n",
    "    return 1/t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trajs = generate_test_data(10000, 5)\n",
    "traj0 = trajs[0]\n",
    "traj0[[i for i in range(20)],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LAG=[1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "n_centers = 100\n",
    "\n",
    "L,centers = Clustering(traj0,n_centers)\n",
    "centers = np.array(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ts = []\n",
    "for i in range(len(LAG)):\n",
    "    C_lag = sliding_window(L,LAG[i])\n",
    "    #print(C_lag)\n",
    "    T_lag = T_reversible(C_lag)\n",
    "    #print(np.sort(np.linalg.eig(T_lag)[0]))\n",
    "    Ts.append(T_lag)\n",
    "plot_timescales(Ts,LAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosen_lag = 13\n",
    "C_lag = sliding_window(L,chosen_lag)\n",
    "T_lag = T_reversible(C_lag)\n",
    "T=T_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eig_val, eig_vec = np.linalg.eig(T)\n",
    "plt.plot(np.absolute(eig_val),'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_pcca_states = 3\n",
    "pcca=msm.PCCA(T,n_pcca_states)\n",
    "metastable_assignments = pcca.metastable_assignment\n",
    "metastable_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metastable_sets=pcca.metastable_sets\n",
    "metastable_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTS\n",
    "\n",
    "First, plot the trajectories and the centers that the k-means algorithm produces. Each center\n",
    "represents a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_square(ax):\n",
    "    ax.set_xlim(-2, 2)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    ax.set_xticks([-2, -1, 0, 1, 2])\n",
    "    ax.set_yticks([-2, -1, 0, 1, 2])\n",
    "    ax.set_xlabel(r\"$x$ / a.u.\")\n",
    "    ax.set_ylabel(r\"$y$ / a.u.\")\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "for i in range(len(trajs)):\n",
    "    ax.scatter(trajs[i][::50, 0], trajs[i][::50, 1], c='grey', s=20)\n",
    "ax.scatter(centers[:, 0], centers[:, 1], c='red', s=50)\n",
    "format_square(ax)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, looking at the centers, plot the stationary distribution at each center(state). That is, the long term probability of being in that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5, 5))\n",
    "im = ax.scatter(centers[:, 0], centers[:, 1], c=stat(T), s=200, cmap=mpl.cm.viridis)\n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_label(r\"$\\pi(x,y)$\", fontsize=20)\n",
    "format_square(ax)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_eig_vec = 5\n",
    "eig_vec = np.linalg.eig(T)[1]\n",
    "eig_vec = np.sort(eig_vec)\n",
    "eig_vec = eig_vec[:,[-(i+1) for i in range(n_eig_vec)]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3.5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.scatter(centers[:, 0], centers[:, 1], s=80, c=eig_vec[:, i+1], cmap=mpl.cm.viridis)\n",
    "    format_square(ax)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the different metastable states that pcca has given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5, 5))\n",
    "im = ax.scatter(centers[:, 0], centers[:, 1], c=metastable_assignments, s=200, cmap=mpl.cm.viridis)\n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_ticks(np.arange(n_pcca_states))\n",
    "cbar.set_label(r\"metastable state\", fontsize=20)\n",
    "format_square(ax)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the stationary distribution at each metastable state. That is, the long term probability of\n",
    "being in that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi = stat(T)\n",
    "pi_states = np.array([pi[s].sum() for s in metastable_sets])\n",
    "pi_vec = pi[metastable_assignments]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.5, 5))\n",
    "im = ax.scatter(centers[:,0], centers[:,1], c=pi_vec, s=200, cmap=mpl.cm.viridis)\n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_label(r\"$\\pi($metastable state$)$\", fontsize=20)\n",
    "format_square(ax)\n",
    "fig.tight_layout()\n",
    "print (pi_states)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute a graph with the transitions between states. The size of a state represents\n",
    "the time that is spent in each state. The size of the arrows represent the probability to \n",
    "go from one state to the other (or the number of steps that in media takes to go from one to the other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfpt = np.zeros(shape=(n_pcca_states, n_pcca_states))\n",
    "for i, s1 in enumerate(metastable_sets):\n",
    "    for j, s2 in enumerate(metastable_sets):\n",
    "        if s1 is s2: continue\n",
    "        mfpt[i, j] = mean_first_passage_times(T,s1, s2)\n",
    "\n",
    "arrow_weights = mfpt.copy()\n",
    "nz = mfpt.nonzero()\n",
    "arrow_weights[nz] = 1.0 / arrow_weights[nz]\n",
    "\n",
    "fig, pos = pyemma.plots.plot_network(\n",
    "    arrow_weights, xpos=[2*i for i in range(n_pcca_states)], state_sizes=pi_states,\n",
    "    arrow_labels=mfpt, arrow_label_format=\"%.0f\", arrow_scale=2.0)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
